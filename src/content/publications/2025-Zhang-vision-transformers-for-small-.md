---
title: "Vision Transformers for Small Datasets"
authors: ["Wei Zhang", "Jian Li", "Sarah Johnson"]
year: 2025
venue: "CVPR 2025"
type: "paper"
cover: "../../assets/vit-cover.jpg"
links:
  pdf: "https://arxiv.org/abs/2501.00000"
  code: ""
  website: "https://example.com/vit-small"
  demo: "https://huggingface.co/spaces/example/vit-small-demo"
  slides: ""
  video: ""
badges:
  - { text: "Best Student Paper", type: "gold" }
description: "Vision Transformers (ViT) typically require massive datasets to outperform CNNs. We propose a novel regularization technique and architecture modification that allows ViTs to train effectively on small datasets (e.g., CIFAR-10, Flowers-102) from scratch, achieving state-of-the-art performance."
featured: false
---
Vision Transformers (ViT) typically require massive datasets to outperform CNNs. We propose a novel regularization technique and architecture modification that allows ViTs to train effectively on small datasets (e.g., CIFAR-10, Flowers-102) from scratch, achieving state-of-the-art performance.